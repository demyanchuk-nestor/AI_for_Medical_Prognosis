{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Loq8k-LVl7gL"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/demyanchuk-nestor/AI_for_Medical_Prognosis/blob/master/Week-2/C2W2_A1_Risk Models Using Tree-based Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_QkBI-Ml7gT",
    "outputId": "c354c534-fd68-4e83-a696-e808f8b21565"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/demyanchuk-nestor/AI_for_Medical_Prognosis\n",
    "%cd 'AI_for_Medical_Prognosis/Week-2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92OgKGqSl7gW"
   },
   "source": [
    "# Моделі ризику з використанням дерева рішень\n",
    "\n",
    "Welcome to the second assignment of Course 2!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCYMBb1Wl7gX"
   },
   "source": [
    "## Зміст\n",
    "1. Імпорт пакетів\n",
    "2. Завантажте набір даних\n",
    "3. Дослідіть набір даних\n",
    "4. Робота з відсутніми даними.\n",
    "Вправа 1\n",
    "5. Дерева рішень.\n",
    "Вправа 2\n",
    "6. Випадкові ліси.\n",
    "Вправа 3\n",
    "7. Імпутація\n",
    "8. Аналіз помилок.\n",
    "Вправа 4\n",
    "9. Підходи імпутації.\n",
    "Вправа 5\n",
    "Вправа 6\n",
    "10. Порівняння\n",
    "11. Пояснення: SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdyHrNZeqc18"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1id9x6FmKclN"
   },
   "source": [
    "У цьому завданні ви отримаєте досвід роботи з моделями на основі дерева. Дерево ухвалення рішень (також можуть називатися деревами класифікацій або регресійними деревами) — використовується в галузі статистики та аналізу даних для прогнозних моделей. Структура дерева містить такі елементи: «листя» і «гілки». Дерева рішень широко використовуються в інтелектуальному аналізі даних. Мета полягає в тому, щоб створити модель, яка прогнозує значення цільової змінної на основі декількох змінних на вході. У даній роботі прогнозується 10-річний ризик смерті людей за набором епідеміологічних даних NHANES I (детальний опис цього набору даних можна знайти на веб-сайті CDC). Це складне завдання та чудова перевірка методів машинного навчання, які ми вивчаємо.\n",
    "\n",
    "Виконуючи завдання, ви дізнаєтеся про:\n",
    "\n",
    "Роботу з відсутніми даними\n",
    "\n",
    "Повний аналіз випадку.\n",
    "\n",
    "Імпутацію\n",
    "\n",
    "Дерева рішень\n",
    "\n",
    "Оцінку.\n",
    "\n",
    "Регуляризацію.\n",
    "\n",
    "Випадкові ліси\n",
    "\n",
    "Гіперпараметричне нала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6k2pItifWeK"
   },
   "source": [
    "<a name='1'></a>\n",
    "## 1. Імпорт пакетів\n",
    "Спочатку ми імпортуємо всі звичайні пакети, необхідні для цього завдання.\n",
    "\n",
    "shap — це бібліотека, яка пояснює прогнози, зроблені моделями машинного навчання.\n",
    "\n",
    "sklearn — одна з найпопулярніших бібліотек машинного навчання.\n",
    "\n",
    "itertools дозволяє нам зручно маніпулювати ітерованими об’єктами, такими як списки.\n",
    "\n",
    "pydotplus використовується разом з IPython.display.\n",
    "\n",
    "Image для візуалізації графових структур, таких як дерева рішень.\n",
    "\n",
    "numpy — базовий пакет для наукових обчислень на Python.\n",
    "\n",
    "pandas — це те, що ми використовуватимемо для маніпулювання нашими даними.\n",
    "\n",
    "seaborn — це бібліотека графіків, яка має кілька зручних функцій для візуалізації відсутніх даних.\n",
    "\n",
    "matplotlib — це бібліотека для побудови графіків."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJEfPD6il7ga",
    "outputId": "5daa1c3e-f63f-4d06-c37b-82f1479ba259"
   },
   "outputs": [],
   "source": [
    "!pip install shap==0.42.0 pydotplus six lifelines dill\n",
    "!pip install typing-extensions==4.4.0\n",
    "!pip install graphviz\n",
    "!pip install matplotlib==3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5s0iQ82okBv",
    "outputId": "da9f2d17-3549-4e88-a4da-f18e52daccf8"
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import sklearn\n",
    "import itertools\n",
    "import pydotplus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "\n",
    "# We'll also import some helper functions that will be useful later on.\n",
    "from util import load_data, cindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YckMl2bwg5Hb"
   },
   "source": [
    "<a name='2'></a>\n",
    "## 2. Завантажте набір даних"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrqlr_ZQhnr4"
   },
   "source": [
    "Запустіть наступну клітинку, щоб завантажити набір епідеміологічних даних NHANES I.\n",
    "\n",
    "Цей набір даних містить різні характеристики лікарняних пацієнтів, а також їхні результати, тобто чи померли вони протягом 10 років."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iM2qfgvUs9c_",
    "outputId": "7ac6d73f-1ade-433a-df71-b74c497b7bac"
   },
   "outputs": [],
   "source": [
    "X_dev, X_test, y_dev, y_test = load_data(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Hjrv1iIl7ge"
   },
   "source": [
    "Набір даних було розділено на набір для розробки (або набір для розробників), який ми будемо використовувати для розробки наших моделей ризику, і набір для тестування, який ми будемо використовувати для тестування наших моделей.\n",
    "\n",
    "Далі ми розділили набір розробників на набір для навчання та перевірки відповідно, щоб навчити та налаштувати наші моделі, використовуючи розподіл 75/25 (зверніть увагу, що ми встановили випадковий стан, щоб зробити цей розподіл повторюваним)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKZRwCuol7ge"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6ijpFDIx_I6"
   },
   "source": [
    "<a name='3'></a>\n",
    "## 3. Дослідіть набір даних\n",
    "Першим кроком є ​​ознайомлення з даними. Запустіть наступну клітинку, щоб отримати розмір вашого навчального набору, і подивіться на невеликий зразок.\n",
    "У набір даних входить: Age - вік , Diastolic BP - , Poverty index - , Rase - склад крові, Red blood cells - еритроцити , Sedimentation rate - швидкість згортання, Serum Albumin - сироватковий альбумін, Serum Cholesterol - холестерин, Serum Iron - залізо, Serum Magnesium - магній, Serum Protein - білок, Sex - стать, Sistolic BP - систолічний АТ, TIBC - , TS - , White blood cells - лейкоцити, BMI - , Pulse pressure - пульс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "V4gvn20Gx-pF",
    "outputId": "709d8416-3d40-431c-eeb6-e5347143e240"
   },
   "outputs": [],
   "source": [
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_q2vf4XECvg"
   },
   "source": [
    "Наші результати дослідження будуть залежати від того, чи помер пацієнт протягом 10 років. Запустіть наступну клітинку, щоб побачити цільовий ряд даних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "drkvmcbQD9S5",
    "outputId": "5cc472a5-7504-4637-d699-a8626db76fac"
   },
   "outputs": [],
   "source": [
    "y_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0OwPz5xh-uS"
   },
   "source": [
    "Використовуйте наступну клітинку, щоб розглянути окремі випадки та ознайомитися з особливостями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mms5-w98ykxM",
    "outputId": "8f833c77-76c1-40ff-be3d-e7a62243bcee"
   },
   "outputs": [],
   "source": [
    "i = 10\n",
    "print(X_train.iloc[i,:])\n",
    "print(\"\\nDied within 10 years? {}\".format(y_train.loc[y_train.index[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VTEfpTXpamz"
   },
   "source": [
    "<a name='4'></a>\n",
    "## 4. Робота з відсутніми даними\n",
    "Дивлячись на наші дані в X_train, ми бачимо, що деякі дані відсутні: деякі значення у виводі попередньої комірки позначені як NaN («не число»).\n",
    "\n",
    "Відсутність даних є звичайним явищем під час аналізу даних, що може бути спричинено різними причинами, такими як несправність вимірювального приладу, небажання або нездатність пацієнтів (респондентів) надати інформацію та помилки в процесі збору даних.\n",
    "\n",
    "Давайте розглянемо шаблон відсутніх даних. seaborn є альтернативою matplotlib, яка має деякі зручні функції побудови графіків для аналізу даних. Ми можемо використовувати функцію його карти, щоб легко візуалізувати шаблон відсутніх даних.\n",
    "\n",
    "Запустіть клітинку нижче, щоб побудувати відсутні дані:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SPNsph0HirU-",
    "outputId": "af43653a-39e9-4aff-d35f-41e90e36311a"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(X_train.isnull(), cbar=False)\n",
    "plt.title(\"Training\")\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(X_val.isnull(), cbar=False)\n",
    "plt.title(\"Validation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUrurkDul7gk"
   },
   "source": [
    "Для кожної функції, представленої у вигляді стовпця, наявні значення відображаються чорним кольором, а відсутні значення встановлюються світлим кольором.\n",
    "\n",
    "На цьому графіку ми бачимо, що для систолічного артеріального тиску (систолічного АТ) бракує багатьох значень."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ak3wbWAQl7gk"
   },
   "source": [
    "<a name='Ex-1'></a>\n",
    "### Вправа 1\n",
    "У клітинці нижче напишіть функцію для обчислення частки випадків із відсутніми даними. Це допоможе нам вирішити, як ми оброблятимемо ці відсутні дані в майбутньому."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZwYAMGr_khG"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qofe71kyl7gl"
   },
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li> The <code>pandas.DataFrame.isnull()</code> method is helpful in this case.</li>\n",
    "    <li> Use the <code>pandas.DataFrame.any()</code> method and set the <code>axis</code> parameter.</li>\n",
    "    <li> Divide the total number of rows with missing data by the total number of rows. Remember that in Python, <code>True</code> values are equal to 1.</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLfV7B8OyWBR"
   },
   "outputs": [],
   "source": [
    "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def fraction_rows_missing(df):\n",
    "    '''\n",
    "    Return percent of rows with any missing\n",
    "    data in the dataframe.\n",
    "\n",
    "    Input:\n",
    "        df (dataframe): a pandas dataframe with potentially missing data\n",
    "    Output:\n",
    "        frac_missing (float): fraction of rows with missing data\n",
    "    '''\n",
    "    ### START CODE HERE (REPLACE 'Pass' with your 'return' code) ###\n",
    "    return sum(df.isnull().any(axis=1)) / len(df)\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yE-rq6Il7gm"
   },
   "source": [
    "Перевірте свою функцію, запустивши клітинку нижче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0U6tjKIkxaGy",
    "outputId": "d4086ce2-58ff-490a-8a27-df6aa2cbbdb3"
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({'a':[None, 1, 1, None], 'b':[1, None, 0, 1]})\n",
    "print(\"Example dataframe:\\n\")\n",
    "print(df_test)\n",
    "\n",
    "print(\"\\nComputed fraction missing: {}, expected: {}\".format(fraction_rows_missing(df_test), 0.75))\n",
    "print(f\"Fraction of rows missing from X_train: {fraction_rows_missing(X_train):.3f}\")\n",
    "print(f\"Fraction of rows missing from X_val: {fraction_rows_missing(X_val):.3f}\")\n",
    "print(f\"Fraction of rows missing from X_test: {fraction_rows_missing(X_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBXhCGRZjCzM"
   },
   "source": [
    "Ми бачимо, що в наших наборах длям навчання та перевірки відсутні значення, але, для нашого тестового набору ми використаємо повні випадки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvYzlx7rlG-R"
   },
   "source": [
    "На першому етапі ми почнемо з аналізу повного випадку, видаливши всі рядки з відсутніми даними. Запустіть наступну клітинку, щоб вилучити ці рядки з нашого курсу та наборів перевірки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1Ev-eq83hP_"
   },
   "outputs": [],
   "source": [
    "X_train_dropped = X_train.dropna(axis='rows')\n",
    "y_train_dropped = y_train.loc[X_train_dropped.index]\n",
    "X_val_dropped = X_val.dropna(axis='rows')\n",
    "y_val_dropped = y_val.loc[X_val_dropped.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDVUZ810pFNQ"
   },
   "source": [
    "<a name='5'></a>\n",
    "## 5. Дерева рішень\n",
    "Дерева рішень у машинному навчанні використовуються як передбачувальні моделі, що відображають знання про об'єкт (представлені гілками) у множину рішень. Це один з підходів до передбачувального моделювання у статистиці, добуванні даних та машинному навчанні.\n",
    "Розповівши про дерева рішень, ми вирішили використовувати класифікатор дерева рішень. Використовуйте scikit-learn, щоб створити дерево рішень для набору даних лікарні пацієнтів які обстежувались упродовж 10 років та за допомогою вибраного навчального набору даних побудувати дерево рішень з прогнозом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "q7qeLJyEpUxF",
    "outputId": "9e285212-6aac-4bb3-c3a7-1c15a4343873"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=None, random_state=10)\n",
    "dt.fit(X_train_dropped, y_train_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5EGqsTCp3OV"
   },
   "source": [
    "Далі ми оцінимо нашу модель. Ми будемо використовувати C-індекс для оцінки.\n",
    "\n",
    "Пам’ятаєте що C-індекс важливий числовий показник, що оцінює здатність моделі диференціювати різні класи шляхом кількісного визначення того, як часто, розглядаючи всі пари пацієнтів (A, B), модель каже, що пацієнт A має вищу оцінка ризику, ніж пацієнт B, коли, згідно з даними спостереження, пацієнт A фактично помер, а пацієнт B фактично живий. У нашому випадку наша модель є двійковим класифікатором, де кожна оцінка ризику дорівнює 1 (модель передбачає, що пацієнт помре), а 0 (що пацієнт буде жити).\n",
    "\n",
    "Більш формально, визначення допустимих пар пацієнтів як пари з різними результатами, узгоджених пар як допустимих пар, де пацієнт, який помер, мав вищий бал ризику (тобто наша модель передбачила 1 для пацієнта, який помер, і 0 для того, хто живий) , і зв’язки як допустимі пари, де показники ризику були рівними (тобто наша модель передбачила 1 для обох пацієнтів або 0 для обох пацієнтів), C-індекс дорівнює:\n",
    "\n",
    "C-Index=#конкордантні пари+0,5×#зв'язки#допустимі пари\n",
    "\n",
    "Запустіть наступну комірку, щоб обчислити C-індекс для курсу та набору перевірки (цього разу ми надали вам реалізацію)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mg9WsT-pqgjZ",
    "outputId": "0971ff8e-5ca9-41e3-f67f-320e86e44f0a"
   },
   "outputs": [],
   "source": [
    "y_train_preds = dt.predict_proba(X_train_dropped)[:, 1]\n",
    "print(f\"Train C-Index: {cindex(y_train_dropped.values, y_train_preds)}\")\n",
    "\n",
    "\n",
    "y_val_preds = dt.predict_proba(X_val_dropped)[:, 1]\n",
    "print(f\"Val C-Index: {cindex(y_val_dropped.values, y_val_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJ4UtZgQqng-"
   },
   "source": [
    "На жаль, здається, що наше дерево перебудоване: воно настільки точно відповідає навчальним даним, що погано узагальнює інші зразки, такі як ті з набору перевірки.\n",
    "\n",
    "Навчальний C-індекс виходить рівним 1,0, оскільки під час ініціалізації DecisionTreeClasifier ми залишили max_depth і min_samples_split невизначеними. Таким чином, побудоване дерево рішень буде продовжувати розщеплюватись настільки далеко, наскільки це можливо, що майже гарантує точну відповідність навчальним даним.\n",
    "\n",
    "Щоб впоратися з цим, ви можете змінити деякі гіперпараметри даного дерева."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nV9d5VDSl7gq"
   },
   "source": [
    "<a name='Ex-2'></a>\n",
    "### Вправа 2\n",
    "Спробуйте знайти набір гіперпараметрів, який покращує узагальнення набору перевірки, і повторно обчисліть C-індекс. Якщо ви все зробите правильно, ви повинні отримати C-індекс вище 0,6 для набору перевірки.\n",
    "\n",
    "Ви можете звернутися до документації для sklearn DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABbqQTPSl7gr"
   },
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li> Try limiting the depth of the tree (<code>'max_depth'</code>).</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhbNgoVpzNod"
   },
   "outputs": [],
   "source": [
    "# Experiment with different hyperparameters for the DecisionTreeClassifier\n",
    "# until you get a c-index above 0.6 for the validation set\n",
    "dt_hyperparams = {\n",
    "    # set your own hyperparameters below, such as 'min_samples_split': 1\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    'max_depth': 3,\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzO-2H3fzCJ2"
   },
   "source": [
    "Запустіть наступну клітинку, щоб підібрати та оцінити регульоване дерево."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r3D0uCBll7hW",
    "outputId": "b26b76ee-5b68-4881-c9c1-1fa82c2ac937"
   },
   "outputs": [],
   "source": [
    "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "dt_reg = DecisionTreeClassifier(**dt_hyperparams, random_state=10)\n",
    "dt_reg.fit(X_train_dropped, y_train_dropped)\n",
    "\n",
    "y_train_preds = dt_reg.predict_proba(X_train_dropped)[:, 1]\n",
    "y_val_preds = dt_reg.predict_proba(X_val_dropped)[:, 1]\n",
    "print(f\"Train C-Index: {cindex(y_train_dropped.values, y_train_preds)}\")\n",
    "print(f\"Val C-Index (expected > 0.6): {cindex(y_val_dropped.values, y_val_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2ofWJB76j9B"
   },
   "source": [
    "Якщо ви використали низьку max_depth, ви можете надрукувати все дерево. Це забезпечує легку інтерпретацію. Запустіть наступну клітинку, щоби побудувати дерево рішень.\n",
    "Дерево рішень є дуже схожим на блок-схему. Використовуючи блок-схему, ви починаєте з початкової точки або кореня діаграми, а потім, залежно від того, як ви відповідаєте критеріям фільтрації цього початкового вузла, ви переходите до одного з наступних можливих вузлів. Цей процес повторюється, поки не буде досягнуто потрібного результату."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "GY-15i0b4MKw",
    "outputId": "04d0fcf6-ea0a-4af1-985d-1d6be2570c04"
   },
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(dt_reg, feature_names=X_train_dropped.columns, out_file=dot_data,\n",
    "                filled=True, rounded=True, proportion=True, special_characters=True,\n",
    "                impurity=False, class_names=['neg', 'pos'], precision=2)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRk9FtGxl7hY"
   },
   "source": [
    "> **Overfitting, underfitting, and the bias-variance tradeoff**\n",
    "\n",
    ">Переобладнання, недообладнання та компроміс зсуву\n",
    "\n",
    "Алгоритми для дерев рішень\n",
    "Дерева рішень працюють на основі алгоритмічного підходу, який розбиває набір даних на окремі точки даних на основі різних критеріїв. Ці розбиття виконуються за допомогою різних змінних або різних функцій набору даних.\n",
    "Рішення дерев часто корисні коли необхідно провести класифікацію, але основним обмеженням є час обчислення. Дерева рішень можуть чітко визначити, які функції у вибраних наборах даних мають найбільшу передбачувану силу. Крім того, на відміну від багатьох алгоритмів машинного навчання, де правила, що використовуються для класифікації даних, важко інтерпретувати, дерева рішень можуть відтворювати інтерпретовані правила.\n",
    "Якщо ви протестували кілька значень max_depth, ви, можливо, побачили, що значення 3 дає C-індекси навчання та перевірки приблизно 0,689 та 0,630, а max_depth 2 дає кращу узгодженість із значеннями приблизно 0,653 та 0,607. В останньому випадку ми ще більше зменшили переобладнання ціною незначної втрати прогнозної продуктивності.\n",
    "\n",
    "Порівняйте це зі значенням max_depth 1, що призводить до C-індексів приблизно 0,597 для навчального набору та 0,598 для набору перевірки: ми усунули надмірне оснащення, але зі значно сильнішим погіршенням прогнозної продуктивності.\n",
    "\n",
    "Нижча прогностична продуктивність на наборах для навчання та тестування вказує на те, що модель недостатньо підходить для даних: вона не вчиться достатньо з навчальних даних і не може узагальнити невидимі дані (тестувальну вибірку в нашому випадку).\n",
    "\n",
    "Пошук моделі, яка мінімізує та прийнятно врівноважує незбалансованість та налаштування (наприклад, вибір моделі з max_depth 2 порівняно з іншими значеннями) є поширеною проблемою в машинному навчанні, яка відома як компроміс зміщення-дисперсії."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FQOUmmwtNtX"
   },
   "source": [
    "<a name='6'></a>\n",
    "## 6. Випадкові ліси\n",
    "\n",
    "Random forest (англ. випадковий ліс) — ансамблевий метод машинного навчання для класифікації, регресії та інших завдань, який працює за допомогою побудови численних дерев прийняття рішень під час тренування моделі й продукує моду для класів (класифікацій) або усереднений прогноз (регресія) побудованих дерев.\n",
    "\n",
    "Незалежно від того, як ви обираєте гіперпараметри, одне дерево рішень схильне до перетворення. Щоб вирішити цю проблему, ви можете спробувати випадкові ліси, які поєднують прогнози з багатьох різних дерев для створення надійного класифікатора.\n",
    "\n",
    "Як і раніше, ми будемо використовувати scikit-learn для створення випадкового лісу для даних. Ми будемо використовувати гіперпараметри за замовчуванням."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "OKQco4cItPY2",
    "outputId": "525a0ed0-34a5-40b6-8849-29b19f6a1d3e"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=10)\n",
    "rf.fit(X_train_dropped, y_train_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYu0LeEww2lV"
   },
   "source": [
    "Тепер обчисліть і повідомте C-індекс для випадкового лісу в наборі для навчання та перевірки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ehZ4LRbw8Un",
    "outputId": "9b39e05c-3508-4406-bcc2-69d81998946a"
   },
   "outputs": [],
   "source": [
    "y_train_rf_preds = rf.predict_proba(X_train_dropped)[:, 1]\n",
    "print(f\"Train C-Index: {cindex(y_train_dropped.values, y_train_rf_preds)}\")\n",
    "\n",
    "y_val_rf_preds = rf.predict_proba(X_val_dropped)[:, 1]\n",
    "print(f\"Val C-Index: {cindex(y_val_dropped.values, y_val_rf_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkcdnwYgw80C"
   },
   "source": [
    "Навчання створення випадкового лісу з гіперпараметрами за замовчуванням призводить до моделі, яка має кращу прогностичну продуктивність, ніж окремі дерева рішень, як у попередньому розділі, але ця модель є надмірною.\n",
    "\n",
    "Тому нам потрібно налаштувати (або оптимізувати) гіперпараметри, щоб знайти модель, яка має хорошу прогностичну продуктивність і мінімізує переобладнання.\n",
    "\n",
    "Гіперпараметри, які ми виберемо для налаштування, будуть такими:\n",
    "\n",
    "n_estimators: кількість дерев, які використовуються в лісі.\n",
    "max_depth: максимальна глибина кожного дерева.\n",
    "min_samples_leaf: мінімальна кількість (якщо int) або частка (якщо float) зразків у аркуші.\n",
    "Підхід, який ми застосовуємо для налаштування гіперпараметрів, відомий як пошук по сітці:\n",
    "\n",
    "Ми визначаємо набір можливих значень для кожного з цільових гіперпараметрів.\n",
    "\n",
    "Модель навчається та оцінюється для кожної можливої ​​комбінації гіперпараметрів.\n",
    "\n",
    "Повертається найефективніший набір гіперпараметрів.\n",
    "\n",
    "Комірка нижче реалізує пошук у сітці гіперпараметрів із використанням C-індексу для оцінки кожної перевіреної моделі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eHX56jeLzvA7"
   },
   "outputs": [],
   "source": [
    "def holdout_grid_search(clf, X_train_hp, y_train_hp, X_val_hp, y_val_hp, hyperparams, fixed_hyperparams={}):\n",
    "    '''\n",
    "    Conduct hyperparameter grid search on hold out validation set. Use holdout validation.\n",
    "    Hyperparameters are input as a dictionary mapping each hyperparameter name to the\n",
    "    range of values they should iterate over. Use the cindex function as your evaluation\n",
    "    function.\n",
    "\n",
    "    Input:\n",
    "        clf: sklearn classifier\n",
    "        X_train_hp (dataframe): dataframe for training set input variables\n",
    "        y_train_hp (dataframe): dataframe for training set targets\n",
    "        X_val_hp (dataframe): dataframe for validation set input variables\n",
    "        y_val_hp (dataframe): dataframe for validation set targets\n",
    "        hyperparams (dict): hyperparameter dictionary mapping hyperparameter\n",
    "                            names to range of values for grid search\n",
    "        fixed_hyperparams (dict): dictionary of fixed hyperparameters that\n",
    "                                  are not included in the grid search\n",
    "\n",
    "    Output:\n",
    "        best_estimator (sklearn classifier): fitted sklearn classifier with best performance on\n",
    "                                             validation set\n",
    "        best_hyperparams (dict): hyperparameter dictionary mapping hyperparameter\n",
    "                                 names to values in best_estimator\n",
    "    '''\n",
    "    best_estimator = None\n",
    "    best_hyperparams = {}\n",
    "\n",
    "    # hold best running score\n",
    "    best_score = 0.0\n",
    "\n",
    "    # get list of param values\n",
    "    lists = hyperparams.values()\n",
    "\n",
    "    # get all param combinations\n",
    "    param_combinations = list(itertools.product(*lists))\n",
    "    total_param_combinations = len(param_combinations)\n",
    "\n",
    "    # iterate through param combinations\n",
    "    for i, params in enumerate(param_combinations, 1):\n",
    "        # fill param dict with params\n",
    "        param_dict = {}\n",
    "        for param_index, param_name in enumerate(hyperparams):\n",
    "            param_dict[param_name] = params[param_index]\n",
    "\n",
    "        # create estimator with specified params\n",
    "        estimator = clf(**param_dict, **fixed_hyperparams)\n",
    "\n",
    "        # fit estimator\n",
    "        estimator.fit(X_train_hp, y_train_hp)\n",
    "\n",
    "        # get predictions on validation set\n",
    "        preds = estimator.predict_proba(X_val_hp)\n",
    "\n",
    "        # compute cindex for predictions\n",
    "        estimator_score = cindex(y_val_hp, preds[:,1])\n",
    "\n",
    "        print(f'[{i}/{total_param_combinations}] {param_dict}')\n",
    "        print(f'Val C-Index: {estimator_score}\\n')\n",
    "\n",
    "        # if new high score, update high score, best estimator\n",
    "        # and best params\n",
    "        if estimator_score >= best_score:\n",
    "                best_score = estimator_score\n",
    "                best_estimator = estimator\n",
    "                best_hyperparams = param_dict\n",
    "\n",
    "    # add fixed hyperparamters to best combination of variable hyperparameters\n",
    "    best_hyperparams.update(fixed_hyperparams)\n",
    "\n",
    "    return best_estimator, best_hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QW77-9jl7hc"
   },
   "source": [
    "<a name='Ex-3'></a>\n",
    "### Вправа 3\n",
    "У клітинці нижче визначте значення, за якими потрібно запустити пошук сітки гіперпараметрів, і запустіть клітинку, щоб знайти найефективніший набір гіперпараметрів.\n",
    "\n",
    "Ваше завдання — отримати C-індекс вище 0,6 як на тренуванні, так і на перевірці."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGf1GWHLl7hc"
   },
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>n_estimators: try values greater than 100</li>\n",
    "    <li>max_depth: try values in the range 1 to 100</li>\n",
    "    <li>min_samples_leaf: try float values below .5 and/or int values greater than 2</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jWiOJI8l7hd"
   },
   "outputs": [],
   "source": [
    "def random_forest_grid_search(X_train_dropped, y_train_dropped, X_val_dropped, y_val_dropped):\n",
    "\n",
    "    # Define ranges for the chosen random forest hyperparameters\n",
    "    hyperparams = {\n",
    "\n",
    "        ### START CODE HERE (REPLACE array values with your code) ###\n",
    "\n",
    "        # how many trees should be in the forest (int)\n",
    "        'n_estimators': [100, 150, 200],\n",
    "\n",
    "        # the maximum depth of trees in the forest (int)\n",
    "\n",
    "        'max_depth': [3, 4, 5],\n",
    "\n",
    "        # the minimum number of samples in a leaf as a fraction\n",
    "        # of the total number of samples in the training set\n",
    "        # Can be int (in which case that is the minimum number)\n",
    "        # or float (in which case the minimum is that fraction of the\n",
    "        # number of training set samples)\n",
    "        'min_samples_leaf': [3, 4],\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "    }\n",
    "\n",
    "\n",
    "    fixed_hyperparams = {\n",
    "        'random_state': 10,\n",
    "    }\n",
    "\n",
    "    rf = RandomForestClassifier\n",
    "\n",
    "    best_rf, best_hyperparams = holdout_grid_search(rf, X_train_dropped, y_train_dropped,\n",
    "                                                    X_val_dropped, y_val_dropped, hyperparams,\n",
    "                                                    fixed_hyperparams)\n",
    "\n",
    "    print(f\"Best hyperparameters:\\n{best_hyperparams}\")\n",
    "\n",
    "\n",
    "    y_train_best = best_rf.predict_proba(X_train_dropped)[:, 1]\n",
    "    print(f\"Train C-Index: {cindex(y_train_dropped, y_train_best)}\")\n",
    "\n",
    "    y_val_best = best_rf.predict_proba(X_val_dropped)[:, 1]\n",
    "    print(f\"Val C-Index: {cindex(y_val_dropped, y_val_best)}\")\n",
    "\n",
    "    # add fixed hyperparamters to best combination of variable hyperparameters\n",
    "    best_hyperparams.update(fixed_hyperparams)\n",
    "\n",
    "    return best_rf, best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6irXWOPUl7hd",
    "outputId": "8613d70d-dea5-4586-e8e3-6a430fae1c2a"
   },
   "outputs": [],
   "source": [
    "best_rf, best_hyperparams = random_forest_grid_search(X_train_dropped, y_train_dropped, X_val_dropped, y_val_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hTrzOWH3zl2"
   },
   "source": [
    "Нарешті, оцініть модель на тестовому наборі. Це важливий крок, оскільки випробування багатьох комбінацій гіперпараметрів і їх оцінка на перевірочному наборі може призвести до того, що модель переповнить перевірочний набір. Тому нам потрібно перевірити, чи добре модель працює на невидимих ​​даних, що є роллю тестового набору, яку ми виконували досі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjkGhi9n32tS",
    "outputId": "711afa03-c5e0-4f1c-a260-88b089b0095c"
   },
   "outputs": [],
   "source": [
    "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "y_test_best = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Test C-Index: {cindex(y_test.values, y_test_best)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAgU3KY5CEEp"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KD063TAhl7hf"
   },
   "source": [
    "Your C-Index on the test set should be greater than `0.6`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsHviHfFKiD8"
   },
   "source": [
    "<a name='7'></a>\n",
    "## 7. Імпутація\n",
    "Тепер ви створили й оптимізували модель випадкового лісу на основі наших даних. Проте падіння тестового індексу C все одно спостерігалося. Можливо, ви викинули більше половини наших даних через відсутність значень систолічного артеріального тиску. Натомість ми можемо спробувати заповнити або врахувати ці значення.\n",
    "\n",
    "По-перше, давайте дослідимо, чи наші дані випадково відсутні чи ні. Давайте побудуємо гістограми випущених рядків проти кожної з коваріат (окрім систолічного артеріального тиску), щоб побачити, чи є тенденція. Порівняйте їх із гістограмами об’єкта в усьому наборі даних. Спробуйте побачити, чи одна з коваріат має суттєво різний розподіл у двох підмножинах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "e2iej2zLl7hg",
    "outputId": "5ee5638a-c2c8-4b75-9cc3-e60e08bc39b8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dropped_rows = X_train[X_train.isnull().any(axis=1)]\n",
    "\n",
    "columns_except_Systolic_BP = [col for col in X_train.columns if col not in ['Systolic BP']]\n",
    "\n",
    "for col in columns_except_Systolic_BP:\n",
    "    sns.distplot(X_train.loc[:, col], norm_hist=True, kde=False, label='full data')\n",
    "    sns.distplot(dropped_rows.loc[:, col], norm_hist=True, kde=False, label='without missing data')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OFcONx8TbNn"
   },
   "source": [
    "Більшість коваріатів розподіляються подібним чином незалежно від того, чи ми відкинули рядки з відсутніми даними. Іншими словами, відсутність даних не залежить від цих коваріатів.\n",
    "\n",
    "Якби це було правдою для всіх коваріантів, тоді можна було б сказати, що дані повністю відсутні (MCAR).\n",
    "\n",
    "Але, розглядаючи коваріату віку, ми бачимо, що набагато більше даних, як правило, не вистачає для пацієнтів старше 65 років. Причина може полягати в тому, що артеріальний тиск вимірювався рідше для літніх людей, щоб уникнути додаткового навантаження на них.\n",
    "\n",
    "Оскільки відсутність пов’язана з однією або декількома коваріантами, відсутні дані називаються випадковими (MAR).\n",
    "\n",
    "Проте, виходячи з наявної у нас інформації, немає підстав вважати, що значення відсутніх даних — або, зокрема, значення відсутніх систолічних артеріальних тисків — пов’язані з віком пацієнтів. Якби це було так, тоді ці дані вважалися б відсутніми не випадково (MNAR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwGi6hXjUCO8"
   },
   "source": [
    "<a name='8'></a>\n",
    "## 8. Аналіз помилок\n",
    "\n",
    "Вправа 4\n",
    "Використовуючи інформацію з наведених вище графіків, спробуйте знайти підгрупу тестових даних, на якій модель працює погано. Ви повинні легко знайти підгрупу з принаймні 250 випадків, для яких модель має C-індекс менше 0,69."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EohoeOcbl7hh"
   },
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li> Define a mask using a feature and a threshold, e.g. patients with a BMI below 20: <code>mask = X_test['BMI'] < 20 </code>. </li>\n",
    "    <li> Try to find a subgroup for which the model had little data.</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzoMtJL604Ni"
   },
   "outputs": [],
   "source": [
    "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def bad_subset(forest, X_test, y_test):\n",
    "    # define mask to select large subset with poor performance\n",
    "    # currently mask defines the entire set\n",
    "\n",
    "    ### START CODE HERE (REPLACE the code after 'mask =' with your code) ###\n",
    "    mask = X_test.Age < 40\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    X_subgroup = X_test[mask]\n",
    "    y_subgroup = y_test[mask]\n",
    "    subgroup_size = len(X_subgroup)\n",
    "\n",
    "    y_subgroup_preds = forest.predict_proba(X_subgroup)[:, 1]\n",
    "    performance = cindex(y_subgroup.values, y_subgroup_preds)\n",
    "\n",
    "    return performance, subgroup_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcMz-ved01uW"
   },
   "source": [
    "#### Перевірте свою роботу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9kW7dj8l7hj",
    "outputId": "e00d9267-9df3-49ab-8c98-62daee0039d5"
   },
   "outputs": [],
   "source": [
    "performance, subgroup_size = bad_subset(best_rf, X_test, y_test)\n",
    "print(\"Subgroup size should greater than 250, performance should be less than 0.69 \")\n",
    "print(f\"Subgroup size: {subgroup_size}, C-Index: {performance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ti4k5YMdl7hk"
   },
   "source": [
    "#### Очікуваний результат\n",
    "Зауважте, ваш фактичний вихід буде відрізнятися залежно від вибраних гіперпараметрів і вибраної маски.\n",
    "\n",
    "Переконайтеся, що c-індекс менше 0,69\n",
    "Розмір підгрупи: 586, C-індекс: 0,6275\n",
    "```\n",
    "\n",
    "**Bonus**:\n",
    "- See if you can get a c-index as low as 0.53\n",
    "```\n",
    "Subgroup size: 251, C-Index: 0.5331\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJ0kcNcXU0Yy"
   },
   "source": [
    "<a name='9'></a>\n",
    "## 9. Підходи імпутації\n",
    "Переконавшись, що наші дані не пропадають абсолютно випадково, ми можемо обробити відсутні значення, замінивши їх заміненими значеннями на основі інших значень, які у нас є. Це відомо як імпутація.\n",
    "\n",
    "Першою стратегією імпутації, яку ми будемо використовувати, є заміна середнього: ми замінимо відсутні значення для кожної ознаки середнім із доступних значень. У наступній комірці скористайтеся SimpleImputer від sklearn, щоб використовувати середнє імпутування для відсутніх значень."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TS1jmsZ2611M"
   },
   "outputs": [],
   "source": [
    "# Impute values using the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(X_train)\n",
    "X_train_mean_imputed = pd.DataFrame(imputer.transform(X_train), columns=X_train.columns)\n",
    "X_val_mean_imputed = pd.DataFrame(imputer.transform(X_val), columns=X_val.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HijIMEJDl7hl"
   },
   "source": [
    "<a name='Ex-5'></a>\n",
    "### Вправа 5\n",
    "Тепер виконайте пошук у сітці гіперпараметрів, щоб знайти найефективнішу модель випадкового лісу, і повідомте про результати для тестового набору.\n",
    "\n",
    "Визначте діапазони параметрів для пошуку гіперпараметрів у наступній клітинці та запустіть клітинку.\n",
    "\n",
    "Цільова продуктивність\n",
    "Зробіть свій індекс с принаймні 0,74 або вище"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyDVo1p9l7hm"
   },
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>n_estimators: try values greater than 100</li>\n",
    "    <li>max_depth: try values in the range 1 to 100</li>\n",
    "    <li>min_samples_leaf: try float values below .5 and/or int values greater than 2</li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEk7pH5vl7hm"
   },
   "outputs": [],
   "source": [
    "# Define ranges for the random forest hyperparameter search\n",
    "hyperparams = {\n",
    "    ### START CODE HERE (REPLACE array values with your code) ###\n",
    "\n",
    "    # how many trees should be in the forest (int)\n",
    "    'n_estimators': [100, 150, 200],\n",
    "\n",
    "    # the maximum depth of trees in the forest (int)\n",
    "    'max_depth': [3, 4, 5],\n",
    "\n",
    "    # the minimum number of samples in a leaf as a fraction\n",
    "    # of the total number of samples in the training set\n",
    "    # Can be int (in which case that is the minimum number)\n",
    "    # or float (in which case the minimum is that fraction of the\n",
    "    # number of training set samples)\n",
    "    'min_samples_leaf': [3, 4],\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqWxFFKgl7hn",
    "outputId": "af661308-8c88-4fbc-9b33-8bf45d9576cf"
   },
   "outputs": [],
   "source": [
    "# UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "rf = RandomForestClassifier\n",
    "\n",
    "rf_mean_imputed, best_hyperparams_mean_imputed = holdout_grid_search(rf, X_train_mean_imputed, y_train,\n",
    "                                                                     X_val_mean_imputed, y_val,\n",
    "                                                                     hyperparams, {'random_state': 10})\n",
    "\n",
    "print(\"Performance for best hyperparameters:\")\n",
    "\n",
    "y_train_best = rf_mean_imputed.predict_proba(X_train_mean_imputed)[:, 1]\n",
    "print(f\"- Train C-Index: {cindex(y_train, y_train_best):.4f}\")\n",
    "\n",
    "y_val_best = rf_mean_imputed.predict_proba(X_val_mean_imputed)[:, 1]\n",
    "print(f\"- Val C-Index: {cindex(y_val, y_val_best):.4f}\")\n",
    "\n",
    "y_test_imp = rf_mean_imputed.predict_proba(X_test)[:, 1]\n",
    "print(f\"- Test C-Index: {cindex(y_test, y_test_imp):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtjHl6K6l7hn"
   },
   "source": [
    "#### Очікуваний результат\n",
    "Зауважте, що ваші фактичні значення с-індексу відрізнятимуться залежно від вибраних гіперпараметрів.\n",
    "\n",
    "Спробуйте отримати хороший тест c-index, подібний до цих цифр нижче:\n",
    "```Python\n",
    "Performance for best hyperparameters:\n",
    "- Train C-Index: 0.8109\n",
    "- Val C-Index: 0.7495\n",
    "- Test C-Index: 0.7805\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8eMe7MY7UJk"
   },
   "source": [
    "Далі ми застосуємо іншу стратегію імпутації, відому як багатовимірна імпутація ознак, використовуючи клас IterativeImputer scikit-learn (див. документацію).\n",
    "\n",
    "За допомогою цієї стратегії для кожної функції, для якої відсутні значення, регресійна модель навчена передбачати спостережувані значення на основі всіх інших ознак, а відсутні значення виводяться за допомогою цієї моделі. Оскільки однієї ітерації для всіх функцій може бути недостатньо для імпутації всіх відсутніх значень, може бути виконано кілька ітерацій, звідси й назва класу IterativeImputer.\n",
    "\n",
    "У наступній комірці використовуйте IterativeImputer, щоб виконати багатовимірне імпутування ознак.\n",
    "\n",
    "Зауважте, що під час першого запуску клітинки imputer.fit(X_train) може виникнути помилка з повідомленням LinAlgError: SVD did not converge: просто повторно запустіть клітинку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwNqehfRl7ho",
    "outputId": "03275ede-ab83-4a81-81b8-99ace6b0510f"
   },
   "outputs": [],
   "source": [
    "# Impute using regression on other covariates\n",
    "imputer = IterativeImputer(random_state=0, sample_posterior=False, max_iter=1, min_value=0)\n",
    "imputer.fit(X_train)\n",
    "X_train_imputed = pd.DataFrame(imputer.transform(X_train), columns=X_train.columns)\n",
    "X_val_imputed = pd.DataFrame(imputer.transform(X_val), columns=X_val.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6BeS7g6l7hp"
   },
   "source": [
    "<a name='Ex-6'></a>\n",
    "### Вправа 6\n",
    "Виконайте пошук у сітці гіперпараметрів, щоб знайти найефективнішу випадкову модель лісу, і повідомте про результати для тестового набору. Визначте діапазони параметрів для пошуку гіперпараметрів у наступній клітинці та запустіть клітинку.\n",
    "\n",
    "Цільова продуктивність\n",
    "Спробуйте отримати c-індекс тексту принаймні 0,74 або вище."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6fsUVAdl7hp"
   },
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>n_estimators: try values greater than 100</li>\n",
    "    <li>max_depth: try values in the range 1 to 100</li>\n",
    "    <li>min_samples_leaf: try float values below .5 and/or int values greater than 2</li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnbmjp98l7hp"
   },
   "outputs": [],
   "source": [
    "# Define ranges for the random forest hyperparameter search\n",
    "hyperparams = {\n",
    "    ### START CODE HERE (REPLACE array values with your code) ###\n",
    "\n",
    "    # how many trees should be in the forest (int)\n",
    "    'n_estimators': [100, 150, 200],\n",
    "\n",
    "    # the maximum depth of trees in the forest (int)\n",
    "    'max_depth': [3, 4, 5],\n",
    "\n",
    "    # the minimum number of samples in a leaf as a fraction\n",
    "    # of the total number of samples in the training set\n",
    "    # Can be int (in which case that is the minimum number)\n",
    "    # or float (in which case the minimum is that fraction of the\n",
    "    # number of training set samples)\n",
    "    'min_samples_leaf': [3, 4],\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9nXvaMcl7hq"
   },
   "source": [
    "Двічі клацніть (або введіть), щоб редагувати"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zEUVluHrl7hq",
    "outputId": "fc2c9fbd-aebe-435b-a1e4-fe89e569da50"
   },
   "outputs": [],
   "source": [
    "# UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "rf = RandomForestClassifier\n",
    "\n",
    "rf_imputed, best_hyperparams_imputed = holdout_grid_search(rf, X_train_imputed, y_train,\n",
    "                                                           X_val_imputed, y_val,\n",
    "                                                           hyperparams, {'random_state': 10})\n",
    "\n",
    "print(\"Performance for best hyperparameters:\")\n",
    "\n",
    "y_train_best = rf_imputed.predict_proba(X_train_imputed)[:, 1]\n",
    "print(f\"- Train C-Index: {cindex(y_train, y_train_best):.4f}\")\n",
    "\n",
    "y_val_best = rf_imputed.predict_proba(X_val_imputed)[:, 1]\n",
    "print(f\"- Val C-Index: {cindex(y_val, y_val_best):.4f}\")\n",
    "\n",
    "y_test_imp = rf_imputed.predict_proba(X_test)[:, 1]\n",
    "print(f\"- Test C-Index: {cindex(y_test, y_test_imp):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDumBgOjl7hr"
   },
   "source": [
    "#### Очікуваний результат\n",
    "Зауважте, ваш фактичний вихід буде відрізнятися залежно від вибраних гіперпараметрів і вибраної маски.\n",
    "\n",
    "Продуктивність для найкращих гіперпараметрів:\n",
    "- Індекс C поїзда: 0,8131\n",
    "- Val C-індекс: 0,7454\n",
    "- Тест C-індекс: 0,7797"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IhZVEMnnmTe"
   },
   "source": [
    "<a name='10'></a>\n",
    "## 10. Порівняння\n",
    "Для хорошої міри повторіть перевірку на попередній підгрупі, щоб побачити, чи ваші нові моделі працюють краще."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdhjRdb1l7hs",
    "outputId": "16a4efc6-6425-46bc-e736-12a8c38ed3ae"
   },
   "outputs": [],
   "source": [
    "performance, subgroup_size = bad_subset(best_rf, X_test, y_test)\n",
    "print(f\"C-Index (no imputation): {performance}\")\n",
    "\n",
    "performance, subgroup_size = bad_subset(rf_mean_imputed, X_test, y_test)\n",
    "print(f\"C-Index (mean imputation): {performance}\")\n",
    "\n",
    "performance, subgroup_size = bad_subset(rf_imputed, X_test, y_test)\n",
    "print(f\"C-Index (multivariate feature imputation): {performance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fvmd2o76yma"
   },
   "source": [
    "Ми повинні побачити, що уникнення повного аналізу випадків (тобто аналізу лише спостережень, для яких немає відсутніх даних) дозволяє нашій моделі трохи краще узагальнювати. Не забувайте досліджувати свої відсутні кейси, щоб визначити, чи вони відсутні випадковим чином чи ні!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFM27SfS1QSD"
   },
   "source": [
    "<a name='11'></a>\n",
    "## 11. Пояснення: SHAP\n",
    "Використання випадкового лісу покращило результати, але ми втратили частину природної інтерпретації дерев. У цьому розділі ми спробуємо пояснити прогнози за допомогою трохи складніших методів.\n",
    "\n",
    "Ви вирішили застосувати *SHAP (додаткові пояснення SHapley) *, передовий метод, який пояснює прогнози, зроблені моделями машинного навчання чорної скриньки (тобто моделями, які є надто складними, щоб бути зрозумілими людьми).\n",
    "\n",
    "З огляду на передбачення, зроблене моделлю машинного навчання, значення SHAP пояснюють передбачення кількісним визначенням додаткової важливості кожної функції для прогнозу. Значення SHAP беруть свій початок у теорії кооперативних ігор, де значення використовуються для кількісної оцінки внеску кожного гравця в гру.\n",
    "\n",
    "Незважаючи на те, що обчислювати значення SHAP для загальних моделей чорної скриньки дорого, у випадку дерев і лісів існує швидкий поліноміальний алгоритм. Щоб отримати докладнішу інформацію, перегляньте статтю TreeShap.\n",
    "\n",
    "Ми використаємо бібліотеку shap, щоб зробити це для нашої моделі випадкового лісу. Запустіть наступну клітинку, щоб вивести осіб із найбільшим ризиком у тестовому наборі відповідно до нашої моделі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "emlK-wlyJEel",
    "outputId": "36dd98fd-9811-432a-9aea-8f7c64ea7093"
   },
   "outputs": [],
   "source": [
    "X_test_risk = X_test.copy(deep=True)\n",
    "X_test_risk.loc[:, 'risk'] = rf_imputed.predict_proba(X_test_risk)[:, 1]\n",
    "X_test_risk = X_test_risk.sort_values(by='risk', ascending=False)\n",
    "X_test_risk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aefDv0PDKrfv"
   },
   "source": [
    "Ми можемо використовувати значення SHAP, щоб спробувати зрозуміти результати моделі на конкретних індивідуумах, використовуючи графіки сил. Проведіть по клітинці нижче, щоб побачити графік впливу на найбільш ризиковану особу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "elJX1FqWKzYm",
    "outputId": "9c86abe1-fb7f-4eda-c4a4-0561e92d620f"
   },
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(rf_imputed)\n",
    "i = 0\n",
    "shap_value = explainer.shap_values(X_test.loc[X_test_risk.index[i], :])[1]\n",
    "shap.force_plot(explainer.expected_value[1], shap_value, feature_names=X_test.columns, matplotlib=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kak4kR4yQ8Tk"
   },
   "source": [
    "Як читати цю таблицю:\n",
    "\n",
    "Червоні секції ліворуч — це функції, які підштовхують модель до кінцевого прогнозу в позитивному напрямку (тобто вищий вік збільшує прогнозований ризик).\n",
    "Сині розділи праворуч — це функції, які штовхають модель до кінцевого прогнозу в негативному напрямку (якщо збільшення функції призводить до зниження ризику, вона буде показана синім кольором).\n",
    "Зауважте, що точні результати вашої діаграми відрізнятимуться залежно від гіперпараметрів, які ви виберете для своєї моделі.\n",
    "Ми також можемо використовувати значення SHAP, щоб зрозуміти результат моделі в сукупності. Запустіть наступну клітинку, щоб ініціалізувати значення SHAP (це може зайняти кілька хвилин)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q9pwTohdRlFB"
   },
   "outputs": [],
   "source": [
    "shap_values = shap.TreeExplainer(rf_imputed).shap_values(X_test)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NpathrHHH3q"
   },
   "source": [
    "Запустіть наступну клітинку, щоб побачити підсумковий графік значень SHAP для кожної функції в кожному з тестових прикладів. Кольори вказують на значення функції."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "id": "ZsqthyxCDfY1",
    "outputId": "366f2bd9-9ad2-49dc-9f72-cd90a8baa712"
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aE_qD7p1l7hw"
   },
   "source": [
    "Ми чітко бачимо, що бути жінкою (стать = 2,0, на відміну від чоловіків, для яких стать = 1,0) має негативне значення SHAP, тобто знижує ризик смерті протягом 10 років. Високий вік і високий систолічний артеріальний тиск мають позитивні значення SHAP і, отже, пов’язані з підвищеною смертністю.\n",
    "\n",
    "Ви можете побачити, як елементи взаємодіють, використовуючи графіки залежностей. Вони відображають значення SHAP для даної функції для кожної точки даних і розфарбовують точки, використовуючи значення для іншої функції. Це дозволяє нам почати пояснювати варіацію значення SHAP для одного значення основної функції.\n",
    "\n",
    "Запустіть наступну клітинку, щоб побачити взаємодію між віком і статтю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "RA3YOaJhEkDZ",
    "outputId": "48844e9b-3954-466f-c7a8-6b6366634799"
   },
   "outputs": [],
   "source": [
    "shap.dependence_plot('Age', shap_values, X_test, interaction_index='Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKei-o-Al7hx"
   },
   "source": [
    "Ми бачимо, що хоча вік > 50 років, як правило, погано (позитивне значення SHAP), бути жінкою, як правило, зменшує вплив віку. Це має сенс, оскільки ми знаємо, що жінки зазвичай живуть довше за чоловіків.\n",
    "\n",
    "Давайте тепер подивимося на індекс бідності та вік."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "tXcUiJ_ZFtcl",
    "outputId": "ca59fc21-9484-43a7-d721-1f5486ef2f92"
   },
   "outputs": [],
   "source": [
    "shap.dependence_plot('Poverty index', shap_values, X_test, interaction_index='Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMoI677Vl7hy"
   },
   "source": [
    "Ми бачимо, що вплив індексу бідності швидко спадає, а для людей з вищим доходом вік починає пояснювати значну частину варіацій у впливі індексу бідності.\n",
    "\n",
    "Спробуйте інші пари та подивіться, які ще цікаві стосунки ви можете знайти!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Qj31_mFiSB_"
   },
   "source": [
    "# Щиро вітаю!\n",
    "Ви виконали цікаве завдання з даного курсу. У даній роботі ви навчилися складати дерева рішень, випадкові ліси та працювати з відсутніми даними.\n",
    "Дерева рішень - це важливий інструмент в прийнятті рішень, який використовується у багатьох галузях, включаючи бізнес, науку, технології, медицину та інші. Основна мета дерев рішень - систематизувати інформацію та визначити оптимальний варіант дії в умовах невизначеності або складності."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "AI4MC2-2"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
